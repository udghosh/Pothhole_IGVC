{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "white_pothole.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOOIOYgmnV0YUaNP8+bNNke",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/udghosh/Pothhole_IGVC/blob/main/white_pothole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdjwzUHCA7D-"
      },
      "source": [
        "#_training_code\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.layers import flatten\n",
        "\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda, ELU,GlobalAveragePooling2D, regularizers\n",
        "from keras.layers.convolutional import Convolution2D, Cropping2D, Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.optimizers import adam\n",
        "from sklearn.utils import shuffle\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "import time, cv2, glob\n",
        "\n",
        "global inputShape,size\n",
        "\n",
        "def kerasModel4():\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(16, (8, 8), strides=(4, 4), padding='valid', input_shape=(size,size,1)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Conv2D(32, (5, 5), padding=\"same\"))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        # model.add(Dropout(.2))\n",
        "        # model.add(Activation('relu'))\n",
        "        # model.add(Dense(1024))\n",
        "        # model.add(Dropout(.5))\n",
        "        model.add(Dense(512))\n",
        "        model.add(Dropout(.1))\n",
        "        model.add(Activation('relu'))\n",
        "        # model.add(Dense(256))\n",
        "        # model.add(Dropout(.5))\n",
        "        # model.add(Activation('relu'))\n",
        "        model.add(Dense(2))\n",
        "        model.add(Activation('softmax'))\n",
        "        return model\n",
        "\n",
        "size=300\n",
        "\n",
        " ## load Training data : pothole\n",
        "potholeTrainImages = glob.glob(\"E:/Major 7sem/pothole-and-plain-rode-images/My Dataset/train/Pothole/*.jpg\")\n",
        "potholeTrainImages.extend(glob.glob(\"E:/Major 7sem/pothole-and-plain-rode-images/My Dataset/train/Pothole/*.jpeg\"))\n",
        "potholeTrainImages.extend(glob.glob(\"E:/Major 7sem/pothole-and-plain-rode-images/My Dataset/train/Pothole/*.png\"))\n",
        "\n",
        "train1 = [cv2.imread(img,0) for img in potholeTrainImages]\n",
        "for i in range(0,len(train1)):\n",
        "    train1[i] = cv2.resize(train1[i],(size,size))\n",
        "temp1 = np.asarray(train1)\n",
        "\n",
        "\n",
        "#  ## load Training data : non-pothole\n",
        "nonPotholeTrainImages = glob.glob(\"E:/Major 7sem/pothole-and-plain-rode-images/My Dataset/train/Plain/*.jpg\")\n",
        "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.jpeg\"))\n",
        "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.png\"))\n",
        "train2 = [cv2.imread(img,0) for img in nonPotholeTrainImages]\n",
        "for i in range(0,len(train2)):\n",
        "    train2[i] = cv2.resize(train2[i],(size,size))\n",
        "temp2 = np.asarray(train2)\n",
        "\n",
        "\n",
        "\n",
        "## load Testing data : non-pothole\n",
        "nonPotholeTestImages = glob.glob(\"E:/Major 7sem/pothole-and-plain-rode-images/My Dataset/test/Plain/*.jpg\")\n",
        "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.jpeg\"))\n",
        "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.png\"))\n",
        "test2 = [cv2.imread(img,0) for img in nonPotholeTestImages]\n",
        "for i in range(0,len(test2)):\n",
        "    test2[i] = cv2.resize(test2[i],(size,size))\n",
        "temp4 = np.asarray(test2)\n",
        "\n",
        "\n",
        "## load Testing data : potholes\n",
        "potholeTestImages = glob.glob(\"E:/Major 7sem/pothole-and-plain-rode-images/My Dataset/test/Pothole/*.jpg\")\n",
        "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.jpeg\"))\n",
        "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.png\"))\n",
        "test1 = [cv2.imread(img,0) for img in potholeTestImages]\n",
        "for i in range(0,len(test1)):\n",
        "    test1[i] = cv2.resize(test1[i],(size,size))\n",
        "temp3 = np.asarray(test1)\n",
        "\n",
        "\n",
        "X_train = []\n",
        "X_train.extend(temp1)\n",
        "X_train.extend(temp2)\n",
        "X_train = np.asarray(X_train)\n",
        "\n",
        "X_test = []\n",
        "X_test.extend(temp3)\n",
        "X_test.extend(temp4)\n",
        "X_test = np.asarray(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_train1 = np.ones([temp1.shape[0]],dtype = int)\n",
        "y_train2 = np.zeros([temp2.shape[0]],dtype = int)\n",
        "y_test1 = np.ones([temp3.shape[0]],dtype = int)\n",
        "y_test2 = np.zeros([temp4.shape[0]],dtype = int)\n",
        "\n",
        "print(y_train1[0])\n",
        "print(y_train2[0])\n",
        "print(y_test1[0])\n",
        "print(y_test2[0])\n",
        "\n",
        "y_train = []\n",
        "y_train.extend(y_train1)\n",
        "y_train.extend(y_train2)\n",
        "y_train = np.asarray(y_train)\n",
        "\n",
        "y_test = []\n",
        "y_test.extend(y_test1)\n",
        "y_test.extend(y_test2)\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "\n",
        "X_train,y_train = shuffle(X_train,y_train)\n",
        "X_test,y_test = shuffle(X_test,y_test)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], size, size, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], size, size, 1)\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "\n",
        "print(\"train shape X\", X_train.shape)\n",
        "print(\"train shape y\", y_train.shape)\n",
        "\n",
        "inputShape = (size, size, 1)\n",
        "model = kerasModel4()\n",
        "\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "\n",
        "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=1000,validation_split=0.1)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "metricsTrain = model.evaluate(X_train, y_train)\n",
        "print(\"Training Accuracy: \",metricsTrain[1]*100,\"%\")\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "metricsTest = model.evaluate(X_test,y_test)\n",
        "print(\"Testing Accuracy: \",metricsTest[1]*100,\"%\")\n",
        "\n",
        "print(\"Saving model weights and configuration file\")\n",
        "model.save('latest_full_model.h5')\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}